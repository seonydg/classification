{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "from ipywidgets import interact\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 확인 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 92 10\n",
      "['./data/Cat/cat.4.jpg', './data/Dog/dog.20.jpg', './data/Cat/cat.158.jpg', './data/Cat/cat.75.jpg', './data/Cat/cat.152.jpg']\n"
     ]
    }
   ],
   "source": [
    "cat_dir = './data/Cat/'\n",
    "dog_dir = './data/Dog/'\n",
    "\n",
    "cat_image_path = sorted([os.path.join(cat_dir, f) for f in os.listdir(cat_dir)])\n",
    "dog_image_path = sorted([os.path.join(dog_dir, f) for f in os.listdir(dog_dir)])\n",
    "\n",
    "image_file_path = [*cat_image_path, *dog_image_path]\n",
    "correct_image_path = [i for i in image_file_path if cv2.imread(i) is not None]\n",
    "\n",
    "random.seed(29)\n",
    "random.shuffle(correct_image_path)\n",
    "\n",
    "train_image_files = correct_image_path[:400]\n",
    "val_image_files = correct_image_path[400:-10]\n",
    "test_image_files = correct_image_path[-10:]\n",
    "print(len(train_image_files), len(val_image_files), len(test_image_files))\n",
    "print(train_image_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ab236f4a5e4fb7bab207c24c36685f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=399), Output()), _dom_classes=('widget-inter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(index=(0, len(train_image_files)-1))\n",
    "def image_show(index=0):\n",
    "    image = train_image_files[index]\n",
    "    image = cv2.imread(image)\n",
    "    print('image shape: ', image.shape)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.title(train_image_files[index].split('/')[-1].split('.')[0])\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_trasnforms, MyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_image_files, transforms=build_trasnforms(image_size=image_size, mean=mean, std=std), phase='train')\n",
    "val_dataset = MyDataset(val_image_files, transforms=build_trasnforms(image_size=image_size, mean=mean, std=std), phase='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) 0\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.__getitem__(0)[0].size(), train_dataset.__getitem__(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) tensor([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "dataloaders = {}\n",
    "\n",
    "dataloaders['train'] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dataloaders['val'] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "image, label = next(iter(dataloaders['train']))\n",
    "print(image.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
